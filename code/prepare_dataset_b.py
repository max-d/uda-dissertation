# -*- coding: utf-8 -*-
"""prepare-dataset-b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZDcvcVvQ4z8y3MgBmHkMsbURpgUo0pue
"""

!pip install ftw-tools

!pip install tifffile imagecodecs

"""#1. Mount Google Drive

"""

from google.colab import drive
drive.mount("/content/drive")

!ftw data download --countries spain

import rasterio
import matplotlib.pyplot as plt
import pathlib as Path
import random
from scipy.ndimage import label
from skimage.color import label2rgb
import numpy as np

# check GPU
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

import os

# import libs for processing images
import imageio
import imagecodecs
from PIL import Image

# import visualizations
import matplotlib.pyplot as plt

import numpy as np # for using np arrays

# TF and co
import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.losses import binary_crossentropy
from sklearn.model_selection import train_test_split

import os
import tifffile
import numpy as np
import imagecodecs
import rasterio

def LoadAndProcessData(image_dir, mask_dir, mask_channel_index=0, mask_dtype=np.uint8, limit=100000):
    """
    Loads original images and processes corresponding multi-channel masks
    for semantic segmentation from specified directories.

    Args:
        image_dir (str): Path to the directory containing original image files.
        mask_dir (str): Path to the directory containing multi-channel mask files.
        mask_channel_index (int): The index of the channel containing the
                                  semantic segmentation labels (e.g., 0 for
                                  AI4Boundaries 'vector label'). Defaults to 0.
        mask_dtype (numpy.dtype): The target integer data type for the final
                                  mask (e.g., np.uint8, np.int64). Defaults to np.uint8.

    Returns:
        tuple: A tuple containing two lists:
            - loaded_images (list): A list of loaded original images (NumPy arrays).
            - processed_masks (list): A list of loaded and processed single-channel
                                     integer masks (NumPy arrays).
    """
    try:
        # List and sort filenames to ensure matching pairs
        image_filenames = sorted(os.listdir(image_dir))
        mask_filenames = sorted(os.listdir(mask_dir))

        # Basic check for equal number of files
        if len(image_filenames) != len(mask_filenames):
            print(f"Warning: Mismatch in file count! Images: {len(image_filenames)}, Masks: {len(mask_filenames)}")
            # Depending on requirements, you might want to raise an error here

        print(f"Found {len(image_filenames)} potential image/mask pairs.")

        loaded_images = []
        processed_masks = []
        cnt = 0
        # Iterate through the pairs using zip for safety
        for img_fname, mask_fname in zip(image_filenames, mask_filenames):
            # Optional: More robust check if names should match exactly (excluding extension)
            img_base = os.path.splitext(img_fname)[0]
            mask_base = os.path.splitext(mask_fname)[0]
            #if img_base != mask_base:
            #    print(f"Warning: Filenames might not correspond? Skipping pair: '{img_fname}' and '{mask_fname}'")
            #    continue

            img_full_path = os.path.join(image_dir, img_fname)
            mask_full_path = os.path.join(mask_dir, mask_fname)

            try:
                # --- Load Original Image ---
                # Using tifffile assuming images might also be TIFFs.
                # If images are standard PNG/JPG, imageio might be slightly simpler,
                # but tifffile handles various TIFF types well.
                with rasterio.open(img_full_path) as src:
                    window_a = src.read()[0:3, :, :]  # Reading first 3 bands
                    image_data = window_a.transpose(1, 2, 0) / 3000  # Normalizing

                #with rasterio.open(window_b_file) as src:
                #    window_b = src.read()[0:3, :, :]  # Reading first 3 bands
                 #   window_b = window_b.transpose(1, 2, 0) / 3000  # Normalizing

                # Load semantic and instance data
                with rasterio.open(mask_full_path) as src:
                    semantic_2_class = src.read()

                multi_channel_mask_data = semantic_2_class
                #image_data = tifffile.imread(img_full_path)
                # Note: Add any necessary preprocessing for images here (e.g., normalization) later.

                # --- Load and Process Mask ---
                # 1. Read the full multi-channel mask data
                #multi_channel_mask_data = tifffile.imread(mask_full_path)

                # 2. Select the relevant channel
                if multi_channel_mask_data.ndim == 3 and multi_channel_mask_data.shape[2] > mask_channel_index:
                    raw_mask = multi_channel_mask_data[:, :, mask_channel_index]
                elif multi_channel_mask_data.ndim == 2 and mask_channel_index == 0:
                    # Handle case where mask file might already be single channel
                    print(f"  Info: Mask '{mask_fname}' is already 2D, using as is.")
                    raw_mask = multi_channel_mask_data
                else:
                    # Error if dimensions/channel index are unexpected
                    print(f"Error: Mask '{mask_fname}' has unexpected shape {multi_channel_mask_data.shape} or invalid channel index {mask_channel_index}. Skipping pair.")
                    continue # Skip this image/mask pair

                # 3. Convert the extracted mask channel to the target integer format
                final_mask = raw_mask.astype(mask_dtype)

                # Append the successfully loaded data
                loaded_images.append(image_data)
                processed_masks.append(semantic_2_class[0])

                cnt += 1

                if cnt >= limit:
                  print("Reached provessing limit of ", limit)
                  break

            except FileNotFoundError:
                print(f"Error: File not found for pair. Image: '{img_full_path}', Mask: '{mask_full_path}'. Skipping.")
            except Exception as e:
                # Catch other potential errors during file reading or processing
                print(f"Error processing pair: Image='{img_fname}', Mask='{mask_fname}'. Error: {e}. Skipping.")

    except FileNotFoundError as e:
        print(f"Error: Cannot access directory. Path: {e.filename}")
        return [], [] # Return empty lists if directories aren't found
    except Exception as e:
        print(f"An unexpected error occurred in LoadAndProcessData: {e}")
        return [], [] # Return empty lists on other unexpected errors

    print(f"Successfully loaded {len(loaded_images)} image/mask pairs.")
    return loaded_images, processed_masks

import cv2 # Using OpenCV for resizing numeric arrays
import numpy as np
from PIL import Image # For mask processing

def PreprocessData(loaded_images, processed_masks, target_shape_img, target_shape_mask):
    m = len(loaded_images)
    if m == 0:
        print("Warning: No images/masks provided.")
        # Return empty arrays with correct shape definition
        return np.zeros((0, *target_shape_img), dtype=np.float32), np.zeros((0, *target_shape_mask[:2], target_shape_mask[2]), dtype=np.int32)


    i_h, i_w, i_c = target_shape_img
    m_h, m_w, m_c = target_shape_mask

    if m_c != 1:
         print(f"Warning: target_shape_mask expects {m_c} channels, but semantic segmentation usually requires 1.")

    X = np.zeros((m, i_h, i_w, i_c), dtype=np.float32)
    y = np.zeros((m, m_h, m_w, m_c), dtype=np.int32)

    print(f"Preprocessing {m} image/mask pairs...")

    for index, (img_array, mask_array) in enumerate(zip(loaded_images, processed_masks)):
        try:
            # --- Debug Input ---
            print(f"Input index {index}: dtype={img_array.dtype}, shape={img_array.shape}, min={np.min(img_array)}, max={np.max(img_array)}")

            # --- Process Image ---

            # 1. Convert to float32 IMMEDIATELY
            img_array_f32 = img_array.astype(np.float32)

            # 2. Resize image using cv2.resize (works well with float32)
            # Ensure 3 channels for RGB processing if not already
            if img_array_f32.ndim == 2:
                 img_array_f32 = cv2.cvtColor(img_array_f32, cv2.COLOR_GRAY2RGB)
            elif img_array_f32.shape[2] == 1:
                 img_array_f32 = cv2.cvtColor(img_array_f32, cv2.COLOR_GRAY2RGB)

            # Check if resize is needed
            if img_array_f32.shape[0] != i_h or img_array_f32.shape[1] != i_w:
                 img_resized_array = cv2.resize(img_array_f32, (i_w, i_h), interpolation=cv2.INTER_LINEAR)
            else:
                 img_resized_array = img_array_f32 # No resize needed


            # 3. Normalize/Scale image data to 0-1 range
            # Based on observed max ~2.5. Using 2.5 or slightly higher (e.g., 3.0) as the divisor.
            # Adjust this value if 2.5 isn't the consistent maximum across your dataset.
            scale_divisor = 2.5 # Or 3.0, or np.max(img_resized_array) if calculated per image
            scaled_image = img_resized_array / scale_divisor

            # 4. Clip to ensure values are strictly within [0.0, 1.0]
            scaled_image = np.clip(scaled_image, 0.0, 1.0)

            # 5. Assign to output array
            X[index] = scaled_image # Already float32

            # --- Process Mask (Keep using PIL for NEAREST neighbor) ---
            # Ensure mask is 2D uint8 for PIL
            if mask_array.ndim == 3 and mask_array.shape[2] == 1:
                mask_array = np.squeeze(mask_array, axis=-1) # Remove channel dim
            if mask_array.ndim != 2:
                 raise ValueError(f"Mask at index {index} has unexpected shape {mask_array.shape} after squeeze.")

            # Convert mask to uint8 if it's not (e.g., could be int32)
            if mask_array.dtype != np.uint8:
                 # Check range before converting - are labels large?
                 print(f"Warning: Mask {index} dtype is {mask_array.dtype}. Converting to uint8. Max label: {np.max(mask_array)}")
                 if np.max(mask_array) > 255:
                     print(f"ERROR: Mask {index} has labels > 255, cannot safely convert to uint8 for PIL.")
                     # Handle error - skip, clip, raise?
                     continue # Skip this pair
                 mask_array = mask_array.astype(np.uint8)

            pil_mask = Image.fromarray(mask_array) # Mode 'L'
            # Resize mask using NEAREST
            if pil_mask.size != (m_w, m_h):
                 pil_mask_resized = pil_mask.resize((m_w, m_h), Image.Resampling.NEAREST)
            else:
                 pil_mask_resized = pil_mask # No resize needed

            mask_resized_array = np.array(pil_mask_resized) # Shape (m_h, m_w)

            # Add the channel dimension and ensure correct dtype (int32)
            y[index] = np.expand_dims(mask_resized_array, axis=-1).astype(np.int32)

        except Exception as e:
            print(f"Error processing data at index {index}: {e}")
            # Consider more robust error handling if needed
            # Setting the corresponding X, y entries to zero or removing them
            X[index] = 0 # Mark image as invalid
            y[index] = -1 # Mark mask as invalid (use a value outside expected classes)


    print("Finished preprocessing.")
    # Optionally filter out failed pairs if marked above
    # valid_indices = np.where(np.all(y != -1, axis=(1,2,3)))[0] # Example if using -1 marker
    # X = X[valid_indices]
    # y = y[valid_indices]

    return X, y

import os
import matplotlib.pyplot as plt
import numpy as np # Make sure numpy is imported
import tifffile # Make sure tifffile is imported for LoadAndProcessData
import imagecodecs # Make sure imagecodecs is imported

# --- Assume LoadAndProcessData function is defined correctly above ---
# def LoadAndProcessData(image_dir, mask_dir, mask_channel_index=0, mask_dtype=np.uint8):
#    ... (your function definition) ...

""" Load Train Set and view some examples """
# Define paths
IMAGE_TRAIN_PATH = './data/ftw/spain/s2_images/window_b' # Use consistent variable names
MASK_TRAIN_PATH = './data/ftw/spain/label_masks/semantic_2class/'
img, mask = [], []
# Call the new function to load data into NumPy arrays
# Ensure the paths exist before calling
if os.path.exists(IMAGE_TRAIN_PATH) and os.path.exists(MASK_TRAIN_PATH):
    print("Loading data using LoadAndProcessData...")
    # The variables 'img' and 'mask' will hold lists of NumPy arrays
    img, mask = LoadAndProcessData(IMAGE_TRAIN_PATH, MASK_TRAIN_PATH, mask_channel_index=0, mask_dtype=np.uint8, limit=2432)
else:
    print(f"Error: Training directories not found at '{IMAGE_TRAIN_PATH}' or '{MASK_TRAIN_PATH}'")
    img, mask = [], [] # Assign empty lists to prevent further errors

# Check if loading was successful and data exists
if img and mask:
    # View an example of image and corresponding mask
    show_images = min(5, len(img)) # Show up to 2 images, or fewer if less data loaded
    print(f"\nDisplaying {show_images} example(s):")
    for i in range(show_images):
        # --- CORRECTED PART (AGAIN) ---
        # Directly use the NumPy arrays already loaded in the lists 'img' and 'mask'
        img_view = img[i]
        mask_view = mask[i]
        # ------------------------------

        print(f"\nImage {i}:")
        print(f"  Shape: {img_view.shape}, dtype: {img_view.dtype}")
        print(f"Mask {i}:")
        print(f"  Shape: {mask_view.shape}, dtype: {mask_view.dtype}")
        print(f"  Unique mask values: {np.unique(mask_view)}")

        # Plotting
        fig, arr = plt.subplots(1, 2, figsize=(15, 7)) # Adjusted figsize for better layout

        # Display image
        arr[0].imshow(img_view)
        arr[0].set_title(f'Image {i}')
        arr[0].axis('off') # Hide axes ticks

        # Display mask
        arr[1].imshow(mask_view, cmap='viridis',vmin=0, vmax=2) # Or cmap='gray'

        arr[1].set_title(f'Processed Mask {i} (Channel 0)')
        arr[1].axis('off') # Hide axes ticks

        plt.tight_layout() # Adjust spacing
        plt.show()
else:
    print("\nNo data loaded, skipping display.")

"""Prepare train dataset"""

# Define the desired shape (Height, Width, Channels)
target_shape_img = [256, 256, 3]
target_shape_mask = [256, 256, 1] # Semantic segmentation mask typically has 1 channel

# Ensure 'img' and 'mask' contain the NumPy arrays loaded by LoadAndProcessData
# Example: Assuming 'img' and 'mask' are already populated from the previous step
if 'img' in locals() and 'mask' in locals() and img and mask: # Check if lists exist and are not empty
    # Process data using the NEW function - notice no path1/path2 arguments
    X_train, y_train = PreprocessData(img, mask, target_shape_img, target_shape_mask)

    # --- Keep the rest of your QC/Visualization code ---
    if X_train.size > 0 and y_train.size > 0 : # Check if processing yielded data
        total_pixels = y_train.size
        unique_classes, counts = np.unique(y_train, return_counts=True)
        print("\nClass distribution in y_train (after resizing):")
        for cls, count in zip(unique_classes, counts):
            percentage = (count / total_pixels) * 100
            print(f"  Class {cls}: {count} pixels ({percentage:.2f}%)")

        # QC the shape of output
        print("\nProcessed Shapes:")
        print("X_train Shape:", X_train.shape)
        print("y_train shape:", y_train.shape)

        # Visualize the output
        image_index = 0 # Visualize the first processed image/mask
        print(f"\nVisualizing processed example index {image_index}:")
        fig, arr = plt.subplots(1, 2, figsize=(10, 5)) # Adjusted figsize

        print(f"Data type: {X_train[image_index].dtype}")
        print(f"Shape: {X_train[image_index].shape}")
        print(f"Min value: {np.min(X_train[image_index])}")
        print(f"Max value: {np.max(X_train[image_index])}")
        print(f"Mean value: {np.mean(X_train[image_index])}") #
        # Display processed image (normalized, 0-1 float)
        arr[0].imshow(X_train[image_index])
        arr[0].set_title('Processed Image')
        arr[0].axis('off')

        # Display processed mask (integer class IDs)
        # Squeeze removes the last dimension (1) for displaying a 2D mask image
        arr[1].imshow(np.squeeze(y_train[image_index]), cmap='viridis') # Use a colormap
        arr[1].set_title('Processed Mask')
        arr[1].axis('off')

        plt.tight_layout()
        plt.show()
    else:
        print("\nPreprocessing resulted in empty arrays. Check logs for errors.")
else:
    print("\nVariables 'img' and 'mask' not found or are empty. Run LoadAndProcessData first.")

!rm -rf ./dataset

from PIL import Image

output_directory = "dataset/train/b"

NUM_IMAGES = 1500 # Matches your provided X_train dimension
IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256, 256, 3
NUM_CLASSES = 2 # Example: 0: background, 1: classA, 2: classB, 3: classC
                # IMPORTANT: Update NUM_CLASSES to the actual number of unique classes in your masks

# Output directories
output_images_directory = "dataset/train/b/images"
output_masks_directory = "dataset/train/b/masks"

# Create output directories if they don't exist
os.makedirs(output_images_directory, exist_ok=True)
os.makedirs(output_masks_directory, exist_ok=True)

# --- Color Map for Masks (Optional, but recommended for better visualization) ---
# Define a color for each class ID. Ensure you have enough colors for NUM_CLASSES.
# Format: [R, G, B]
# Class 0 will usually be background, often black.
color_map = [
    [0, 0, 0],        # Class 0 (e.g., background) - Black
    [128, 0, 0],      # Class 1 - Maroon
    [0, 128, 0],      # Class 2 - Green
    [0, 0, 128],      # Class 3 - Navy
    # Add more colors if NUM_CLASSES > 4
    [128, 128, 0],    # Class 4 - Olive
    [128, 0, 128],    # Class 5 - Purple
    [0, 128, 128],    # Class 6 - Teal
    [192, 192, 192],  # Class 7 - Silver
]
# Ensure color_map has enough entries
if NUM_CLASSES > len(color_map):
    print(f"Warning: NUM_CLASSES ({NUM_CLASSES}) is greater than the number of defined colors ({len(color_map)}).")
    print("Add more colors to 'color_map' or masks for higher classes might not be colored distinctly.")
    # Extend with random colors if needed (not ideal for consistency)
    for _ in range(NUM_CLASSES - len(color_map)):
        color_map.append(list(np.random.randint(50, 200, 3))) # Avoid pure black/white for random


print(f"X_train shape: {X_train.shape}, dtype: {X_train.dtype}")
print(f"y_train shape: {y_train.shape}, dtype: {y_train.dtype}")
print(f"Min value in y_train: {np.min(y_train)}, Max value in y_train: {np.max(y_train)}")
# Verify that max value in y_train is less than NUM_CLASSES
if np.max(y_train) >= NUM_CLASSES:
    print(f"CRITICAL WARNING: Max value in y_train ({np.max(y_train)}) is >= NUM_CLASSES ({NUM_CLASSES}).")
    print("This will lead to errors in color mapping or incorrect class representations.")
    print("Ensure NUM_CLASSES is correctly set to be one greater than the highest class ID in y_train.")


# Determine the number of images/masks to save
num_items_to_save = X_train.shape[0]

# Iterate over each item
for i in range(num_items_to_save):
    # --- 1. Process and Save Original Image (from X_train) ---
    image_array_x = X_train[i]

    # Data type and range conversion for X_train (if necessary, same as before)
    if image_array_x.dtype == np.float32 or image_array_x.dtype == np.float64:
        if np.min(image_array_x) >= 0 and np.max(image_array_x) <= 1:
            image_array_x = (image_array_x * 255).astype(np.uint8)
        elif np.min(image_array_x) >= -1 and np.max(image_array_x) <= 1:
            image_array_x = ((image_array_x + 1) / 2 * 255).astype(np.uint8)
        elif np.min(image_array_x) >= 0 and np.max(image_array_x) <= 255:
             image_array_x = image_array_x.astype(np.uint8)
        else:
            image_array_x = np.clip(image_array_x, 0, 255).astype(np.uint8)
    elif image_array_x.dtype != np.uint8:
        image_array_x = np.clip(image_array_x, 0, 255).astype(np.uint8)

    try:
        pil_image_x = Image.fromarray(image_array_x, 'RGB')
        filename_x = f"image_{str(i).zfill(len(str(num_items_to_save)))}.png"
        filepath_x = os.path.join(output_images_directory, filename_x)
        pil_image_x.save(filepath_x)
    except Exception as e:
        print(f"Error saving X_train image {i}: {e}")
        continue

    # --- 2. Process and Save Segmentation Mask (from y_train) ---
    current_mask_hwc1 = y_train[i] # Shape is (H, W, 1)

    # Squeeze the last dimension to get a 2D mask (H, W) of class indices
    processed_mask_2d = np.squeeze(current_mask_hwc1, axis=-1)

    # Ensure processed_mask_2d is uint8 for Pillow
    if processed_mask_2d.dtype != np.uint8:
        # Class indices should ideally be small integers.
        if np.max(processed_mask_2d) >= 256 or np.min(processed_mask_2d) < 0:
            print(f"Warning: Mask {i} class IDs ({processed_mask_2d.dtype}) are outside uint8 range after processing. Max: {np.max(processed_mask_2d)}, Min: {np.min(processed_mask_2d)}. Clipping.")
        processed_mask_2d = np.clip(processed_mask_2d, 0, 255).astype(np.uint8)
    # else: # Already uint8, no conversion needed unless already done by np.squeeze
    #    processed_mask_2d = processed_mask_2d.astype(np.uint8) # ensure just in case


    # Option A: Save mask as a color-mapped RGB image (Recommended)
    mask_rgb = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
    for class_id_val in range(NUM_CLASSES): # Iterate up to NUM_CLASSES
        if class_id_val < len(color_map):
             mask_rgb[processed_mask_2d == class_id_val] = color_map[class_id_val]
        else:
            # Fallback for classes beyond defined color_map
            # This condition should ideally not be met if NUM_CLASSES and color_map are correctly set
            mask_rgb[processed_mask_2d == class_id_val] = [255, 255, 255] # White, or some other default

    try:
        pil_mask_rgb = Image.fromarray(mask_rgb, 'RGB')
        mask_filename_rgb = f"mask_color_{str(i).zfill(len(str(num_items_to_save)))}.png"
        mask_filepath_rgb = os.path.join(output_masks_directory, mask_filename_rgb)
        pil_mask_rgb.save(mask_filepath_rgb)
    except Exception as e:
        print(f"Error saving color mask for y_train item {i}: {e}")
        continue


    if (i + 1) % (num_items_to_save // 10 if num_items_to_save >= 10 else 1) == 0: # Print progress
        print(f"Saved {i+1}/{num_items_to_save} images and masks.")
        if (i + 1) == num_items_to_save or (i + 1) % (num_items_to_save // 2 if num_items_to_save >=2 else 1) == 0 : # print for first, mid and last
             print(f"  Last image: {filepath_x}")
             print(f"  Last color mask: {mask_filepath_rgb}")
             print(f"  Last gray mask: {mask_filepath_gray}")


print(f"\nFinished saving {num_items_to_save} images to: {output_images_directory}")
print(f"Finished saving {num_items_to_save} masks to: {output_masks_directory}")

!tar -czf datasetb.v2.tar.gz ./dataset

!ls -la

!cp datasetb.v2.tar.gz /content/drive/MyDrive/dissertation/datasets/datasetb.v2.tar.gz