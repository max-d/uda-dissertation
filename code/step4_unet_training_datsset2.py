# -*- coding: utf-8 -*-
"""step4.unet-training-datsset2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19vB5IbaEZAXxwYnPB5mr_eFpVsU91Hat

# Fine-tune Model1 on Dataset AB

## Mount Google Drive
"""

from google.colab import drive
drive.mount("/content/drive")

!ls -la /content/drive/MyDrive/dissertation/datasets/

!cp /content/drive/MyDrive/dissertation/datasets/finetuning_dataset.v2.tar.gz ./

!tar -xzf ./finetuning_dataset.v2.tar.gz

!ls -la ./finetuning_dataset2/train/masks/ | head

# check GPU
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

import os

# import libs for processing images
import imageio
from PIL import Image

# import visualizations
import matplotlib.pyplot as plt

import numpy as np

# TF and co
import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.losses import binary_crossentropy

def load_images(folder_path):

    image_list = []

    if not os.path.isdir(folder_path):
        return np.array([])

    filenames = sorted(os.listdir(folder_path))

    for filename in filenames:


      img_path = os.path.join(folder_path, filename)
      try:
          with Image.open(img_path) as img:

              img_array = np.array(img)
              image_list.append(img_array)


      except Exception as e:
              print(f"Warning: Error processing image {img_path}: {e}. Skipping.")

    if not image_list:
        print("No images were successfully loaded.")
        return np.array([])

    try:

        numpy_array_of_images = np.stack(image_list, axis=0)
        return numpy_array_of_images
    except ValueError as e:
        return np.array([])

masks = load_images('./finetuning_dataset2/train/masks/')

masks.shape

"""### Prepare Masks for learning"""

def create_binary_mask_from_specific_color(rgb_image_array, target_color_rgb):
    if not isinstance(rgb_image_array, np.ndarray) or rgb_image_array.ndim != 3 or rgb_image_array.shape[-1] != 3:
        raise ValueError("Input 'rgb_image_array' must be a NumPy array with shape (H, W, 3).")
    if not isinstance(target_color_rgb, tuple) or len(target_color_rgb) != 3:
        raise ValueError("'target_color_rgb' must be an (R, G, B) tuple.")

    matches = np.all(rgb_image_array == np.array(target_color_rgb), axis=2)
    binary_mask_2d = matches.astype(np.uint8)
    binary_mask_hw1 = np.expand_dims(binary_mask_2d, axis=-1)

    return binary_mask_hw1

target_red = (128, 0, 0)
Y_masks_processed = np.array(
    [create_binary_mask_from_specific_color(masks[i], target_red) for i in range(masks.shape[0])]
)

Y_masks_processed.shape

print(np.unique(Y_masks_processed))

images = load_images('./finetuning_dataset2/train/images')

import numpy as np
from PIL import Image
import os

def PreprocessData(loaded_images, processed_masks, target_shape_img, target_shape_mask):

    m = len(loaded_images)
    if m == 0:
        print("Warning: No images/masks provided to PreprocessData_v2.")
        return np.zeros((0, *target_shape_img), dtype=np.float32), np.zeros((0, *target_shape_mask), dtype=np.int32)

    i_h, i_w, i_c = target_shape_img
    m_h, m_w, m_c = target_shape_mask
    if m_c != 1:
        print(f"Warning: target_shape_mask expects {m_c} channels, but semantic segmentation usually requires 1.")

    X = np.zeros((m, i_h, i_w, i_c), dtype=np.float32)
    y = np.zeros((m, m_h, m_w, m_c), dtype=np.int32)

    print(f"Preprocessing {m} image/mask pairs...")


    for index, (img_array, mask_array) in enumerate(zip(loaded_images, processed_masks)):
        try:

            if img_array.dtype != np.uint8:
                 img_array = img_array.astype(np.uint8)
            pil_img = Image.fromarray(img_array)

            pil_img = pil_img.convert('RGB')
            pil_img_resized = pil_img.resize((i_w, i_h), Image.Resampling.LANCZOS)
            img_resized_array = np.array(pil_img_resized)
            X[index] = img_resized_array.astype(np.float32) / 255.0


            if mask_array.ndim != 2:
                print(f"Warning: Mask at index {index} has {mask_array.ndim} dims, expected 2. Trying first channel.")
                mask_array = mask_array[:, :, 0]
            if mask_array.dtype != np.uint8:
                mask_array = mask_array.astype(np.uint8)
            pil_mask = Image.fromarray(mask_array)
            pil_mask_resized = pil_mask.resize((m_w, m_h), Image.Resampling.NEAREST)
            mask_resized_array = np.array(pil_mask_resized)
            adjusted_mask_array = mask_resized_array
            y[index] = np.expand_dims(adjusted_mask_array, axis=-1).astype(np.int32)

        except Exception as e:
            print(f"Error processing data at index {index}: {e}. Skipping pair.")

    print("Finished preprocessing.")
    return X, y

import os
import matplotlib.pyplot as plt
import numpy as np
import tifffile

img = images
mask = Y_masks_processed

if img.any() and mask.any():
    # View an example of image and corresponding mask
    show_images = min(5, len(img))
    print(f"\nDisplaying {show_images} example(s):")
    for i in range(show_images):

        img_view = img[i]
        mask_view = mask[i]


        print(f"\nImage {i}:")
        print(f"  Shape: {img_view.shape}, dtype: {img_view.dtype}")
        print(f"Mask {i}:")
        print(f"  Shape: {mask_view.shape}, dtype: {mask_view.dtype}")
        print(f"  Unique mask values: {np.unique(mask_view)}")

        fig, arr = plt.subplots(1, 2, figsize=(15, 7))

        # Display image
        arr[0].imshow(img_view)
        arr[0].set_title(f'Image {i}')
        arr[0].axis('off')

        # Display mask
        arr[1].imshow(mask_view, cmap='viridis')
        arr[1].set_title(f'Processed Mask {i} (Channel 0)')
        arr[1].axis('off')

        plt.tight_layout()
        plt.show()
else:
    print("\nNo data loaded, skipping display.")

"""### Prepare train dataset"""

target_shape_img = [256, 256, 3]
target_shape_mask = [256, 256, 1]


if 'img' in locals() and 'mask' in locals() and img.any() and mask.any():

    X_train, y_train = PreprocessData(img, mask, target_shape_img, target_shape_mask)


    if X_train.size > 0 and y_train.size > 0 :
        total_pixels = y_train.size
        unique_classes, counts = np.unique(y_train, return_counts=True)
        print("\nClass distribution in y_train (after resizing):")
        for cls, count in zip(unique_classes, counts):
            percentage = (count / total_pixels) * 100
            print(f"  Class {cls}: {count} pixels ({percentage:.2f}%)")


        print("\nProcessed Shapes:")
        print("X_train Shape:", X_train.shape)
        print("y_train shape:", y_train.shape)


        image_index = 0
        print(f"\nVisualizing processed example index {image_index}:")
        fig, arr = plt.subplots(1, 2, figsize=(10, 5))

        arr[0].imshow(X_train[image_index])
        arr[0].set_title('Processed Image')
        arr[0].axis('off')

        arr[1].imshow(np.squeeze(y_train[image_index]), cmap='viridis')
        arr[1].set_title('Processed Mask')
        arr[1].axis('off')

        plt.tight_layout()
        plt.show()
    else:
        print("\nPreprocessing resulted in empty arrays.")
else:
    print("\nVariables 'img' and 'mask' not found or are empty.")

print(np.unique(y_train))

"""### Prepare validation dataset and show examples"""

from sklearn.model_selection import train_test_split


img_train, img_val, mask_train, mask_val = train_test_split(
    X_train,
    y_train,
    test_size=0.2,
    random_state=42,
    shuffle=True
)

if img_val.any() and mask_val.any():

    show_images = min(5, len(img_val))
    print(f"\nDisplaying {show_images} example(s):")
    for i in range(show_images):

        img_view = img_val[i]
        mask_view = mask_val[i]


        print(f"\nImage {i}:")
        print(f"  Shape: {img_view.shape}, dtype: {img_view.dtype}")
        print(f"Mask {i}:")
        print(f"  Shape: {mask_view.shape}, dtype: {mask_view.dtype}")
        print(f"  Unique mask values: {np.unique(mask_view)}")

        fig, arr = plt.subplots(1, 2, figsize=(15, 7))


        arr[0].imshow(img_view)
        arr[0].set_title(f'Image {i}')
        arr[0].axis('off')

        arr[1].imshow(mask_view, cmap='viridis')
        arr[1].set_title(f'Processed Mask {i} (Channel 0)')
        arr[1].axis('off')

        plt.tight_layout()
        plt.show()
else:
    print("\nNo data loaded, skipping display.")

"""### Download pretrained model from GDrive"""

!ls -la /content/drive/MyDrive/dissertation/

!cp ./drive/MyDrive/dissertation/unet_basic_v2.keras ./

reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',  # Monitor validation loss
    factor=0.2,          # Factor by which the learning rate will be reduced (new_lr = lr * factor)
    patience=3,          # Number of epochs with no improvement after which learning rate will be reduced.
    min_lr=1e-6,         # Lower bound on the learning rate.
    verbose=1,           # Print messages when reducing LR
    mode='min'           # 'min' because we want loss to decrease
)

class LearningRateLogger(tf.keras.callbacks.Callback):
    def on_epoch_begin(self, epoch, logs=None):
        current_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)
        print(f"Epoch {epoch+1}: Learning rate is {current_lr:.7f}.")
    def __init__(self):
        super().__init__()
        self.epoch_lrs = []
    def on_epoch_end(self, epoch, logs=None):
        current_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)
        self.epoch_lrs.append(current_lr)

lr_logger = LearningRateLogger()

class SegF1(tf.keras.metrics.Metric):
    def __init__(self, name="macro_f1", **kw):
        super().__init__(name=name, **kw)
        self.f1 = tf.keras.metrics.F1Score(average="macro", threshold=None)

    def update_state(self, y_true, y_pred, sample_weight=None):
        # flatten to (N,) then expand to (N,1) â†’ now 2-D
        y_true = tf.reshape(y_true, [-1, 1])
        y_pred = tf.reshape(tf.argmax(y_pred, -1), [-1, 1])
        self.f1.update_state(y_true, y_pred, sample_weight)

    def result(self):       return self.f1.result()
    def reset_states(self): self.f1.reset_states()

unetv1 = tf.keras.models.load_model('./unet_basic_v1.keras', custom_objects={"SegF1": SegF1})

"""### Training"""

with tf.device('/device:GPU:0'):
  results = unetv1.fit(
      img_train,
      mask_train,
      batch_size=8,
      epochs=10,
      validation_data=(img_val, mask_val),
      callbacks=[reduce_lr_callback, lr_logger]
      )

import matplotlib.pyplot as plt
fig, axis = plt.subplots(1, 4, figsize=(20, 5))
axis[0].plot(results.history["loss"], color='r', label = 'train loss')
axis[0].plot(results.history["val_loss"], color='b', label = 'val loss')
axis[0].set_title('Loss Comparison')
axis[0].legend()
axis[1].plot(results.history["accuracy"], color='r', label = 'train accuracy')
axis[1].plot(results.history["val_accuracy"], color='b', label = 'val accuracy')
axis[1].set_title('Pixel Accuracy Comparison')
axis[1].legend()
axis[2].plot(results.history["macro_f1"], color='r', label = 'train f1')
axis[2].plot(results.history["val_macro_f1"], color='b', label = 'val f1')
axis[2].set_title('F1 Score Comparison')
axis[2].legend()
axis[3].plot(results.history["crop_iou"], color='r', label = 'train iou')
axis[3].plot(results.history["val_crop_iou"], color='b', label = 'val iou')
axis[3].set_title('IoU Comparison')
axis[3].legend()

"""### Evaluation of trained model"""

unetv1 = tf.keras.models.load_model('./unet_basic_v2.keras', custom_objects={"SegF1": SegF1})

with tf.device('/device:GPU:0'):
  res = unetv1.evaluate(img_val, mask_val)
  print("Evaluation:", res)

# Results of Validation Dataset
def VisualizeResults(index):
    img = img_train[index]
    img = img[np.newaxis, ...]
    pred_y = unetv1.predict(img)
    pred_mask = tf.argmax(pred_y[0], axis=-1)
    pred_mask = pred_mask[..., tf.newaxis]
    fig, arr = plt.subplots(1, 3, figsize=(15, 15))
    arr[0].imshow(img_train[index])
    arr[0].set_title('Processed Image')
    arr[1].imshow(mask_train[index,:,:,0])
    arr[1].set_title('Actual Masked Image ')
    arr[2].imshow(pred_mask[:,:,0])
    arr[2].set_title('Predicted Masked Image ')

index = 19
VisualizeResults(index)

"""### Results

Model was fine tuned and showed improvement on pictures with new style.

Save new model
"""

save_path = './unet_basic_v2.keras'

unetv1.save(save_path)

!ls -la ./

!cp ./unet_basic_v2.keras ./drive/MyDrive/dissertation/unet_basic_v2.keras